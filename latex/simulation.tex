\section{Simulation}
  \subsection{Introduction}
    The outcomes of the analysis of Steemit are here complemented with
    experiments that verify our findings. We have implemented a simulation
    framework that realizes execution of Steemit's post-voting system as defined
    previously.

    In particular, we consider two separate scenarios: First, we simulate the
    case when all players follow the prescribed honest strategy of Steemit,
    investigating how the curation quality of the system varies with the number
    of voting rounds. We successfully reproduce the result of
    Theorem~\ref{theorem:convergence:steem}, which implies that the system
    converges to the ideal post order up to the last post/completely/perfectly
    converges when a sufficient number of voting rounds is permitted, but
    otherwise the resulting list of posts may fail to achieve even
    1-convergence.

    The second case measures how resilient is the curation quality of Steemit to
    dishonest agents. As we have already seen TOFIX, a Steemit user has
    financial benefit in promoting her own posts. A combination of methods
    (apart from striving to produce posts of higher quality) can contribute to
    that end.  Voting for one's own posts, refraining from voting posts created
    by others and obtaining Sybil~\ref{sybilattack} accounts that only vote for
    her posts are only an indicative subset. We thus examine the quality of the
    resulting list when certain users do not follow the honest protocol, but
    apply the aforementioned self-promoting methods. We observe that a small
    increase in the number of selfish players has a detrimental effect to the
    t-convergence metric of the post voting system. Furthermore, we measure the
    number of positions on the list that the selfish post gains with respect to
    the number of selfish players.

  \subsection{Methodology}
    We leverage three metrics to measure the correlation of the curated list and
    the ideal list: Kendall's Tau and Spearman's Rho that are two prominent rank
    corellation coefficients, and $t$-similarity. The last measure is based on
    $t$-convergence. More specifically, a post list has $t$-similarity if the
    first $t$ posts are ordered as they would in any $t$-ideal reordering of the
    post list.

    \subsubsection*{Rank correlation coefficients.}
      To quantify the similarity between two ordered list of posts we employ
      Spearman's Rho and Kendall's Tau, two of the most popular rank correlation
      coefficients~\cite{kendall1955rank}. When measuring rank correlation,
      these coefficients will measure the statistical significance between two
      lists, each producing a value in $\left[-1, 1\right]$. When the ranking of
      two lists is completely unrelated to each other, the rank correlation
      coefficient will be 0. If there exists a correlation, the coefficients
      vary between 1 meaning absolute correlation (i.e. the the lists are
      identical) and -1, meaning absolute inverse correlation (i.e. the lists
      are sorted in reversed order).

    In addition to $t$-similarity and the rank correlation coefficients used in
    the first scenario, in the case of dishonest participants we include a
    metric that measures the gains of the selfish players. In particular, the
    metric is defined as the difference between the real position of the
    ``selfish'' post after the execution and its ranking according to the ideal
    order. We are thus able to measure how advantageous is for users to behave
    selfishly.  Furthermore, $t$-similarity informs us how this behavior
    affects the overall quality of curation of the platform.

  \subsection{Results}

    \subsubsection*{Scenario A: All users are honest}
      The simulation scenario in which all users follow the established protocol
      is an extension of the $t$-convergence bounds obtained in the previous
      section and permits us study the curation problem from a more practical
      perspective.

    \subsubsection{Scenario B: Selfish users}
      The inclusion of selfish actors in our simulation of Steemit permits us
      measuring the system's resilience to deviations of the expected curation
      protocol (i.e. all users voting according to their likability). As
      previously mentioned, we constitute voting rings in which one user, the
      ring leader, creates a number of sybil accounts which will vote firstly
      for the post of the ring leader. In order to understand how the presence
      of voting rings affect the quality of curation of the platform, we run our
      simulations varying key parameters such as the ring size or the ration
      between greedy participants and the total number of users. From our
      analysis in Scenario A, we are able to run the simulation in the most
      relevant curation conditions, such as bounding number of rounds when the
      $t$-convergence is reached.
